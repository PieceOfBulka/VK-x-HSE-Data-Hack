{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-21T13:29:38.544084Z",
     "start_time": "2024-04-21T13:29:38.530204Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# sheets_list = ['kino.mail', 'dom.mail', 'health.mail']\n",
    "# classes_list = ['Культура и Искусство', 'Строительство и Интерьер', 'Красота и Здоровье']\n",
    "# datasets_list = []\n",
    "# for i, target in enumerate(sheets_list):\n",
    "#     current_dataset = pd.read_excel('data.mail.xlsx', sheet_name=target)\n",
    "#     current_dataset['target'] = classes_list[i]\n",
    "#     datasets_list.append(current_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T13:29:38.559686Z",
     "start_time": "2024-04-21T13:29:38.545086Z"
    }
   },
   "id": "b1ae12e2a1bc3ecd",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    text       target\n0      Она меня завораживает. Я бросаю все и всех, ка...  Развлечение\n1      «Рынок азиатских продуктов может выиграть в ре...  Развлечение\n2      Cafezinho do BrasilПолноценный мясной бразильс...  Развлечение\n3      Бычьи хвосты в La bella società\\n«Я решила про...  Развлечение\n4      «Шанти»Ресторан — пионер паназиатской кухни в ...  Развлечение\n...                                                  ...          ...\n26666  Актриса Агата Муцениеце немногословно ответила...  Развлечение\n26667  Селин Дион в личном блоге опубликовала кадр со...  Развлечение\n26668  Председатель Союза театральных деятелей России...  Развлечение\n26669  Настасья Самбурская появится в неожиданном обр...  Развлечение\n26670  Модель и актриса Эмили Ратаковски спровоцирова...  Развлечение\n\n[26671 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Она меня завораживает. Я бросаю все и всех, ка...</td>\n      <td>Развлечение</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>«Рынок азиатских продуктов может выиграть в ре...</td>\n      <td>Развлечение</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Cafezinho do BrasilПолноценный мясной бразильс...</td>\n      <td>Развлечение</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Бычьи хвосты в La bella società\\n«Я решила про...</td>\n      <td>Развлечение</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>«Шанти»Ресторан — пионер паназиатской кухни в ...</td>\n      <td>Развлечение</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>26666</th>\n      <td>Актриса Агата Муцениеце немногословно ответила...</td>\n      <td>Развлечение</td>\n    </tr>\n    <tr>\n      <th>26667</th>\n      <td>Селин Дион в личном блоге опубликовала кадр со...</td>\n      <td>Развлечение</td>\n    </tr>\n    <tr>\n      <th>26668</th>\n      <td>Председатель Союза театральных деятелей России...</td>\n      <td>Развлечение</td>\n    </tr>\n    <tr>\n      <th>26669</th>\n      <td>Настасья Самбурская появится в неожиданном обр...</td>\n      <td>Развлечение</td>\n    </tr>\n    <tr>\n      <th>26670</th>\n      <td>Модель и актриса Эмили Ратаковски спровоцирова...</td>\n      <td>Развлечение</td>\n    </tr>\n  </tbody>\n</table>\n<p>26671 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df = pd.read_csv('marked_dataset.csv')\n",
    "my_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T13:29:40.110942Z",
     "start_time": "2024-04-21T13:29:38.560687Z"
    }
   },
   "id": "ef39c45a900170e3",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Разметка кластеризацией на основе самих текстов\n",
    "2. Потом классификация на двух уровнях абстракции (первый работает быстро по саммаризации и бьет на более крупные классы), а второй точнее (по самому тексту на более точные классы). МЫ МОЖЕМ СДЕЛАТЬ НАЧАЛЬНЫХ КЛАССОВ ПОБОЛЬШЕ В РАЗНЫХ КОМБИНАЦИЯХ\n",
    "3. Саммаризация текстов для извлечения признаков (возможно несколько саммаризаций как в датасете, то есть выделить описание, название статьи и ключевые слова)\n",
    "4. Промты - дополняем текст так, чтобы он хорошо воспринмиался сетью. Один из полходов. М\n",
    "5. Выделить сущности как фичи? \n",
    "\n",
    "Выделить сущности как признаки?\n",
    "\n",
    "В интерфейсе выводить несколько дополнительных тегов (ближайших)\n",
    "Как я и хотел, в итоге надо самостоятельно найти датасет и выделить классысамим, а дали нам только пример.\n",
    "\n",
    "NER для фичей? Или можно в интерфейсе подсвечивать ключевые слова?\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a39716658cd5df70"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Запустим AutoML для классификации на данном нам датасете"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "732efc9ad2f4eb3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Основа классификации текстов - это всегда эмбеддинги, так что нужно упор сделать в методы подбора эмбеддингов предложений (на основе эмбеддингов слов)\n",
    "1. Weighted Average Transformer (WAT)\n",
    "2. Bag of Random Embedding Projections (BOREP)\n",
    "3. Random LSTM – LSTM со случайными весами\n",
    "4. Bert Pooling – получение эмбеддинга с последнего выхода модели Transformer\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef5e5a067e23d0d8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T13:29:40.299101Z",
     "start_time": "2024-04-21T13:29:40.111945Z"
    }
   },
   "id": "15c30b5cd36d4fd1",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Standard python libraries\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "\n",
    "\n",
    "# Installed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# Imports from our package\n",
    "from lightautoml.automl.base import AutoML\n",
    "from lightautoml.ml_algo.boost_lgbm import BoostLGBM\n",
    "from lightautoml.ml_algo.boost_cb import BoostCB\n",
    "from lightautoml.ml_algo.tuning.optuna import OptunaTuner\n",
    "from lightautoml.automl.presets.text_presets import TabularNLPAutoML\n",
    "from lightautoml.pipelines.features.lgb_pipeline import LGBSimpleFeatures\n",
    "from lightautoml.pipelines.ml.base import MLPipeline\n",
    "from lightautoml.pipelines.selection.importance_based import ImportanceCutoffSelector, ModelBasedImportanceEstimator\n",
    "from lightautoml.reader.base import PandasToPandasReader\n",
    "from lightautoml.tasks import Task\n",
    "from lightautoml.automl.blend import WeightedBlender"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T13:29:42.628386Z",
     "start_time": "2024-04-21T13:29:40.300167Z"
    }
   },
   "id": "16849bd77190b5da",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "RANDOM_STATE = 72\n",
    "N_FOLDS = 5\n",
    "N_THREADS = 4\n",
    "\n",
    "roles = {\n",
    "    'target' : 'target',\n",
    "    'text' : 'text',\n",
    "}\n",
    "\n",
    "data_train, data_valid = train_test_split(my_df,  random_state=RANDOM_STATE, test_size=0.7)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T13:29:42.643731Z",
     "start_time": "2024-04-21T13:29:42.629387Z"
    }
   },
   "id": "86c645e22a86acaf",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "task = Task('multiclass', metric='auc')\n",
    "# ‘auc’ - ROC-AUC of each class against the rest.\n",
    "# ‘auc_mu’ - AUC-Mu. Multi-class extension of standard AUC\n",
    "\n",
    "\n",
    "automl = TabularNLPAutoML( \n",
    "    task=task,\n",
    "    timeout=3600,\n",
    "    cpu_limit=4,\n",
    "    gpu_ids='0',\n",
    "    general_params={  # За оптимизацию гиперпараметров отвечает 'nested_cv’: False\n",
    "        'nested_cv': False,\n",
    "        'use_algos': [['linear_l2', 'cb', 'nn']]  # nn - это файтюнинг берта\n",
    "    },\n",
    "    autonlp_params = {'sent_scaler' : 'l2',\n",
    "                      'model_name': 'pooled_bert',\n",
    "                      'transformer_params': {'model_params':\n",
    "                                                 {'pooling': 'mean'},\n",
    "                                             },\n",
    "    },\n",
    "    text_params={   # Change model?\n",
    "        'lang': 'ru',\n",
    "        'bert_model': 'prajjwal1/bert-tiny' #'google-bert/bert-base-uncased' #'prajjwal1/bert-tiny'  # Путь в библиотеке hugging face (БУКВАЛЬНО НАЗВАНИЕ В СПИСКЕ)\n",
    "    },\n",
    "    nn_params={\n",
    "        'opt_params': {'lr': 1e-5},\n",
    "        'max_length': 128,\n",
    "        'bs': 32,\n",
    "        'n_epochs': 10,\n",
    "    },\n",
    "    reader_params={\n",
    "        'cv': N_FOLDS, \n",
    "        'random_state': RANDOM_STATE\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T13:29:50.477142Z",
     "start_time": "2024-04-21T13:29:50.450586Z"
    }
   },
   "id": "714c3a52646e8b53",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:29:51] Stdout logging level is DEBUG.\n",
      "[16:29:53] Model language mode: ru\n",
      "[16:29:53] Task: multiclass\n",
      "\n",
      "[16:29:53] Start automl preset with listed constraints:\n",
      "[16:29:53] - time: 3600.00 seconds\n",
      "[16:29:53] - CPU: 4 cores\n",
      "[16:29:53] - memory: 16 GB\n",
      "\n",
      "[16:29:53] \u001B[1mTrain data shape: (8001, 2)\u001B[0m\n",
      "\n",
      "[16:29:53] Layer \u001B[1m1\u001B[0m train process start. Time left 3599.99 secs\n",
      "[16:30:02] Start fitting \u001B[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001B[0m ...\n",
      "[16:30:02] Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [], 'embed_sizes': (), 'data_size': 100}\n",
      "[16:30:02] ===== Start working with \u001B[1mfold 0\u001B[0m for \u001B[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001B[0m =====\n",
      "[16:30:02] Linear model: C = 1e-05 score = 0.8936112954893621\n",
      "[16:30:02] Linear model: C = 5e-05 score = 0.8936906424471951\n",
      "[16:30:02] Linear model: C = 0.0001 score = 0.8937407809797402\n",
      "[16:30:02] Linear model: C = 0.0005 score = 0.8942031260154673\n",
      "[16:30:02] Linear model: C = 0.001 score = 0.8949647345766074\n",
      "[16:30:02] Linear model: C = 0.005 score = 0.900369264890019\n",
      "[16:30:02] Linear model: C = 0.01 score = 0.9082669348443481\n",
      "[16:30:02] Linear model: C = 0.05 score = 0.946660633075115\n",
      "[16:30:02] Linear model: C = 0.1 score = 0.9579413453158059\n",
      "[16:30:02] Linear model: C = 0.5 score = 0.9716290129587085\n",
      "[16:30:03] Linear model: C = 1 score = 0.9752341781034202\n",
      "[16:30:03] Linear model: C = 5 score = 0.9807957595478494\n",
      "[16:30:03] Linear model: C = 10 score = 0.9807957595478494\n",
      "[16:30:03] Linear model: C = 50 score = 0.9839548807403126\n",
      "[16:30:03] Linear model: C = 100 score = 0.9839548807403126\n",
      "[16:30:03] Linear model: C = 500 score = 0.9839548807403126\n",
      "[16:30:03] ===== Start working with \u001B[1mfold 1\u001B[0m for \u001B[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001B[0m =====\n",
      "[16:30:03] Linear model: C = 1e-05 score = 0.8954690547887749\n",
      "[16:30:03] Linear model: C = 5e-05 score = 0.8948186886770461\n",
      "[16:30:03] Linear model: C = 0.0001 score = 0.8948691763326617\n",
      "[16:30:03] ===== Start working with \u001B[1mfold 2\u001B[0m for \u001B[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001B[0m =====\n",
      "[16:30:04] Linear model: C = 1e-05 score = 0.8885902091099118\n",
      "[16:30:04] Linear model: C = 5e-05 score = 0.888497046456149\n",
      "[16:30:04] Linear model: C = 0.0001 score = 0.8884375052569697\n",
      "[16:30:04] ===== Start working with \u001B[1mfold 3\u001B[0m for \u001B[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001B[0m =====\n",
      "[16:30:04] Linear model: C = 1e-05 score = 0.8969158576436624\n",
      "[16:30:04] Linear model: C = 5e-05 score = 0.8985426506608822\n",
      "[16:30:04] Linear model: C = 0.0001 score = 0.8985831006666546\n",
      "[16:30:04] Linear model: C = 0.0005 score = 0.8993910135520209\n",
      "[16:30:04] Linear model: C = 0.001 score = 0.9001930078495448\n",
      "[16:30:04] Linear model: C = 0.005 score = 0.9054414721501224\n",
      "[16:30:04] Linear model: C = 0.01 score = 0.9121432130572943\n",
      "[16:30:04] Linear model: C = 0.05 score = 0.9544213095926983\n",
      "[16:30:04] Linear model: C = 0.1 score = 0.9662690689511031\n",
      "[16:30:04] Linear model: C = 0.5 score = 0.9792402579489834\n",
      "[16:30:05] Linear model: C = 1 score = 0.9820412215088109\n",
      "[16:30:05] Linear model: C = 5 score = 0.9859979046178469\n",
      "[16:30:05] Linear model: C = 10 score = 0.9859979046178469\n",
      "[16:30:05] Linear model: C = 50 score = 0.9865438247993894\n",
      "[16:30:05] Linear model: C = 100 score = 0.9865438247993894\n",
      "[16:30:05] Linear model: C = 500 score = 0.9865438247993894\n",
      "[16:30:05] ===== Start working with \u001B[1mfold 4\u001B[0m for \u001B[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001B[0m =====\n",
      "[16:30:05] Linear model: C = 1e-05 score = 0.8974725954852291\n",
      "[16:30:05] Linear model: C = 5e-05 score = 0.8975317978916963\n",
      "[16:30:05] Linear model: C = 0.0001 score = 0.8976301812354711\n",
      "[16:30:05] Linear model: C = 0.0005 score = 0.8981829712134088\n",
      "[16:30:05] Linear model: C = 0.001 score = 0.8988100655558436\n",
      "[16:30:06] Linear model: C = 0.005 score = 0.9034414301393614\n",
      "[16:30:06] Linear model: C = 0.01 score = 0.9094581549895582\n",
      "[16:30:06] Linear model: C = 0.05 score = 0.9531034707192474\n",
      "[16:30:06] Linear model: C = 0.1 score = 0.965176531409791\n",
      "[16:30:06] Linear model: C = 0.5 score = 0.9794213807247549\n",
      "[16:30:06] Linear model: C = 1 score = 0.9829653724813306\n",
      "[16:30:06] Linear model: C = 5 score = 0.9876560895275917\n",
      "[16:30:06] Linear model: C = 10 score = 0.9876560895275917\n",
      "[16:30:06] Linear model: C = 50 score = 0.9901283475178371\n",
      "[16:30:06] Linear model: C = 100 score = 0.9901283475178371\n",
      "[16:30:06] Linear model: C = 500 score = 0.9901283475178371\n",
      "[16:30:06] Fitting \u001B[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001B[0m finished. score = \u001B[1m0.9268835988096255\u001B[0m\n",
      "[16:30:07] \u001B[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001B[0m fitting and predicting completed\n",
      "[16:30:07] Time left 3586.26 secs\n",
      "[16:30:08] Feature concated__text fitted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:32<00:00,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:30:41] Feature concated__text transformed\n",
      "[16:30:42] Start fitting \u001B[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001B[0m ...\n",
      "[16:30:42] Training params: {'task_type': 'GPU', 'thread_count': 4, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False, 'devices': '0'}\n",
      "[16:30:42] ===== Start working with \u001B[1mfold 0\u001B[0m for \u001B[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001B[0m =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "AUC is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:30:42] 0:\ttest: 0.6491112\tbest: 0.6491112 (0)\ttotal: 158ms\tremaining: 7m 53s\n",
      "[16:30:44] 100:\ttest: 0.8153717\tbest: 0.8161359 (95)\ttotal: 2.12s\tremaining: 1m\n",
      "[16:30:46] 200:\ttest: 0.8325327\tbest: 0.8331750 (176)\ttotal: 4.05s\tremaining: 56.5s\n",
      "[16:30:48] 300:\ttest: 0.8405305\tbest: 0.8405305 (300)\ttotal: 6.01s\tremaining: 53.9s\n",
      "[16:30:50] 400:\ttest: 0.8481857\tbest: 0.8487311 (388)\ttotal: 7.96s\tremaining: 51.6s\n",
      "[16:30:52] 500:\ttest: 0.8525743\tbest: 0.8525743 (500)\ttotal: 9.95s\tremaining: 49.6s\n",
      "[16:30:54] 600:\ttest: 0.8580345\tbest: 0.8590394 (580)\ttotal: 11.9s\tremaining: 47.6s\n",
      "[16:30:56] 700:\ttest: 0.8587568\tbest: 0.8601895 (649)\ttotal: 13.9s\tremaining: 45.5s\n",
      "[16:30:57] bestTest = 0.8601894884\n",
      "[16:30:57] bestIteration = 649\n",
      "[16:30:57] Shrink model to first 650 iterations.\n",
      "[16:30:57] ===== Start working with \u001B[1mfold 1\u001B[0m for \u001B[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001B[0m =====\n",
      "[16:30:58] 0:\ttest: 0.7010173\tbest: 0.7010173 (0)\ttotal: 22.3ms\tremaining: 1m 6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "AUC is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:31:00] 100:\ttest: 0.7968143\tbest: 0.7968143 (100)\ttotal: 2s\tremaining: 57.5s\n",
      "[16:31:02] 200:\ttest: 0.8233189\tbest: 0.8271959 (192)\ttotal: 3.97s\tremaining: 55.2s\n",
      "[16:31:04] 300:\ttest: 0.8362896\tbest: 0.8362896 (300)\ttotal: 5.95s\tremaining: 53.4s\n",
      "[16:31:06] 400:\ttest: 0.8443198\tbest: 0.8445750 (390)\ttotal: 7.9s\tremaining: 51.2s\n",
      "[16:31:08] 500:\ttest: 0.8476208\tbest: 0.8476208 (500)\ttotal: 9.85s\tremaining: 49.1s\n",
      "[16:31:10] 600:\ttest: 0.8490398\tbest: 0.8512136 (549)\ttotal: 11.8s\tremaining: 47.1s\n",
      "[16:31:12] 700:\ttest: 0.8478697\tbest: 0.8515397 (624)\ttotal: 13.8s\tremaining: 45.2s\n",
      "[16:31:12] bestTest = 0.8515397236\n",
      "[16:31:12] bestIteration = 624\n",
      "[16:31:12] Shrink model to first 625 iterations.\n",
      "[16:31:12] ===== Start working with \u001B[1mfold 2\u001B[0m for \u001B[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001B[0m =====\n",
      "[16:31:13] 0:\ttest: 0.6841978\tbest: 0.6841978 (0)\ttotal: 21.3ms\tremaining: 1m 3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "AUC is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:31:15] 100:\ttest: 0.8306924\tbest: 0.8306924 (100)\ttotal: 2.02s\tremaining: 58s\n",
      "[16:31:17] 200:\ttest: 0.8576392\tbest: 0.8580320 (196)\ttotal: 3.97s\tremaining: 55.3s\n",
      "[16:31:19] 300:\ttest: 0.8666815\tbest: 0.8685315 (281)\ttotal: 5.91s\tremaining: 53s\n",
      "[16:31:21] 400:\ttest: 0.8728923\tbest: 0.8729843 (398)\ttotal: 7.85s\tremaining: 50.9s\n",
      "[16:31:22] 500:\ttest: 0.8722423\tbest: 0.8755441 (422)\ttotal: 9.77s\tremaining: 48.8s\n",
      "[16:31:23] bestTest = 0.8755440837\n",
      "[16:31:23] bestIteration = 422\n",
      "[16:31:23] Shrink model to first 423 iterations.\n",
      "[16:31:23] ===== Start working with \u001B[1mfold 3\u001B[0m for \u001B[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001B[0m =====\n",
      "[16:31:24] 0:\ttest: 0.6760589\tbest: 0.6760589 (0)\ttotal: 22.5ms\tremaining: 1m 7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "AUC is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:31:26] 100:\ttest: 0.8085988\tbest: 0.8085988 (100)\ttotal: 2.06s\tremaining: 59.3s\n",
      "[16:31:28] 200:\ttest: 0.8539931\tbest: 0.8543459 (193)\ttotal: 4.02s\tremaining: 56s\n",
      "[16:31:29] 300:\ttest: 0.8651269\tbest: 0.8659902 (291)\ttotal: 5.95s\tremaining: 53.4s\n",
      "[16:31:31] 400:\ttest: 0.8701555\tbest: 0.8703039 (398)\ttotal: 7.92s\tremaining: 51.4s\n",
      "[16:31:33] 500:\ttest: 0.8702224\tbest: 0.8732550 (480)\ttotal: 9.9s\tremaining: 49.4s\n",
      "[16:31:35] 600:\ttest: 0.8751740\tbest: 0.8751740 (600)\ttotal: 11.9s\tremaining: 47.3s\n",
      "[16:31:37] 700:\ttest: 0.8773196\tbest: 0.8774346 (660)\ttotal: 13.8s\tremaining: 45.3s\n",
      "[16:31:39] 800:\ttest: 0.8818692\tbest: 0.8818692 (800)\ttotal: 15.9s\tremaining: 43.5s\n",
      "[16:31:41] 900:\ttest: 0.8824663\tbest: 0.8835932 (874)\ttotal: 17.8s\tremaining: 41.6s\n",
      "[16:31:43] bestTest = 0.8835932487\n",
      "[16:31:43] bestIteration = 874\n",
      "[16:31:43] Shrink model to first 875 iterations.\n",
      "[16:31:43] ===== Start working with \u001B[1mfold 4\u001B[0m for \u001B[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001B[0m =====\n",
      "[16:31:44] 0:\ttest: 0.6446133\tbest: 0.6446133 (0)\ttotal: 23ms\tremaining: 1m 8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "AUC is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:31:46] 100:\ttest: 0.8116062\tbest: 0.8116062 (100)\ttotal: 2.57s\tremaining: 1m 13s\n",
      "[16:31:48] 200:\ttest: 0.8332051\tbest: 0.8350637 (168)\ttotal: 4.66s\tremaining: 1m 4s\n",
      "[16:31:50] 300:\ttest: 0.8394760\tbest: 0.8400030 (299)\ttotal: 6.68s\tremaining: 59.9s\n",
      "[16:31:53] 400:\ttest: 0.8442819\tbest: 0.8447486 (379)\ttotal: 8.79s\tremaining: 57s\n",
      "[16:31:54] 500:\ttest: 0.8452699\tbest: 0.8467971 (470)\ttotal: 10.8s\tremaining: 53.6s\n",
      "[16:31:56] bestTest = 0.8467970552\n",
      "[16:31:56] bestIteration = 470\n",
      "[16:31:56] Shrink model to first 471 iterations.\n",
      "[16:31:56] Fitting \u001B[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001B[0m finished. score = \u001B[1m0.8737941205303646\u001B[0m\n",
      "[16:31:56] \u001B[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001B[0m fitting and predicting completed\n",
      "[16:31:56] Time left 3476.83 secs\n",
      "[16:31:56] number of text features: 1 \n",
      "[16:31:56] number of categorical features: 0 \n",
      "[16:31:56] number of continuous features: 0 \n",
      "[16:31:56] Start fitting \u001B[1mLvl_0_Pipe_2_Mod_0_TorchNN__linear_layer_0\u001B[0m ...\n",
      "[16:31:56] Training params: {'num_workers': 4, 'pin_memory': False, 'max_length': 128, 'is_snap': False, 'input_bn': False, 'max_emb_size': 50, 'bert_name': 'prajjwal1/bert-tiny', 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'ru', 'deterministic': False, 'multigpu': False, 'random_state': 42, 'model': '_linear_layer', 'model_with_emb': False, 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 10, 'snap_params': {'k': 1, 'early_stopping': True, 'patience': 1, 'swa': False}, 'bs': 32, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'lr': 1e-05}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 5, 'factor': 0.5, 'verbose': True}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'optimization_search_space': None, 'verbose_bar': False, 'freeze_defaults': False, 'n_out': 9, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'embedding_size': 10, 'cat_embedder': 'cat', 'cont_embedder': 'cont', 'stop_by_metric': False, 'device_ids': None, 'num_dims': 0, 'text_features': ['concated__text'], 'bias': array([-0.35805072, -2.13613689, -2.49205626, -3.10399942, -3.79993601,\n",
      "       -4.46553323, -4.65658847, -5.05549618, -5.20313218])}\n",
      "[16:31:56] ===== Start working with \u001B[1mfold 0\u001B[0m for \u001B[1mLvl_0_Pipe_2_Mod_0_TorchNN__linear_layer_0\u001B[0m =====\n",
      "[16:31:58] Last linear layer not founded, so init_bias=False\n",
      "[16:32:36] Epoch: 0, train loss: 2.528212785720825, val loss: 2.0411696434020996, val metric: 0.6259058388618522\n"
     ]
    }
   ],
   "source": [
    "oob_preds = automl.fit_predict(data_train, roles=roles, verbose=5)\n",
    "print('OOB score: {}'.format(roc_auc_score(data_train[roles['target']].values, oob_preds.data, multi_class='ovr')))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-04-21T13:29:51.500812Z"
    }
   },
   "id": "fd731ee6886c401f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.8013454 , 0.23664728, 0.29297793, ..., 0.03079473, 0.03808406,\n       0.12075672], dtype=float32)"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oob_preds.data[:, 0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T16:08:36.217597Z",
     "start_time": "2024-04-20T16:08:36.204839Z"
    }
   },
   "id": "73cd77d9b23b811a",
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print('OOB score: {}'.format(roc_auc_score(data_train[roles['target']].values, oob_preds.data, multi_class=\"ovr\")))\n",
    "test_preds = automl.predict(data_valid, n_jobs=N_THREADS)\n",
    "print(f'TEST score: {roc_auc_score(data_valid[roles[\"target\"]].values, test_preds.data, multi_class=\"ovr\")}')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "322b1d3f9950ae13",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST score: 0.6144871049459633\n"
     ]
    }
   ],
   "source": [
    "print(f'TEST score: {roc_auc_score(data_valid[roles[\"target\"]].values, test_preds.data, multi_class=\"ovr\")}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T16:50:01.207090Z",
     "start_time": "2024-04-20T16:50:01.142546Z"
    }
   },
   "id": "a09bd37be2c96481",
   "execution_count": 87
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Выберем хорошие подходы для классификации текстов."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8761570eee281640"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### BERT Hugging Face"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4872642e3950e66a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "import evaluate\n",
    "from transformers import TrainingArguments, Trainer\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T17:21:55.294186Z",
     "start_time": "2024-04-20T17:21:55.276181Z"
    }
   },
   "id": "f13147a7424716c4",
   "execution_count": 96
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-uncased\", num_labels=4)\n",
    "\n",
    "#  DeepPavlov/rubert-base-cased, google-bert/bert-base-uncased"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T17:21:56.504235Z",
     "start_time": "2024-04-20T17:21:55.912119Z"
    }
   },
   "id": "ec9ed4a31109ca7e",
   "execution_count": 97
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.21.0`: Please run `pip install transformers[torch]` or `pip install accelerate -U`",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[99], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m metric \u001B[38;5;241m=\u001B[39m evaluate\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 2\u001B[0m training_args \u001B[38;5;241m=\u001B[39m \u001B[43mTrainingArguments\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtest_trainer\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevaluation_strategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mepoch\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_metrics\u001B[39m(eval_pred):\n\u001B[0;32m      5\u001B[0m     logits, labels \u001B[38;5;241m=\u001B[39m eval_pred\n",
      "File \u001B[1;32m<string>:125\u001B[0m, in \u001B[0;36m__init__\u001B[1;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, dataloader_persistent_workers, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, gradient_checkpointing_kwargs, include_inputs_for_metrics, eval_do_concat_batches, fp16_backend, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, dispatch_batches, split_batches, include_tokens_per_second, include_num_input_tokens_seen, neftune_noise_alpha, optim_target_modules)\u001B[0m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\training_args.py:1605\u001B[0m, in \u001B[0;36mTrainingArguments.__post_init__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1599\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m version\u001B[38;5;241m.\u001B[39mparse(version\u001B[38;5;241m.\u001B[39mparse(torch\u001B[38;5;241m.\u001B[39m__version__)\u001B[38;5;241m.\u001B[39mbase_version) \u001B[38;5;241m==\u001B[39m version\u001B[38;5;241m.\u001B[39mparse(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m2.0.0\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfp16:\n\u001B[0;32m   1600\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m--optim adamw_torch_fused with --fp16 requires PyTorch>2.0\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1602\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   1603\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mframework \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1604\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m is_torch_available()\n\u001B[1;32m-> 1605\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[38;5;241m.\u001B[39mtype \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1606\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice\u001B[38;5;241m.\u001B[39mtype \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmlu\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1607\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice\u001B[38;5;241m.\u001B[39mtype \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnpu\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1608\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice\u001B[38;5;241m.\u001B[39mtype \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxpu\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1609\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (get_xla_device_type(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice) \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGPU\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCUDA\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m   1610\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfp16 \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfp16_full_eval)\n\u001B[0;32m   1611\u001B[0m ):\n\u001B[0;32m   1612\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1613\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1614\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m (`--fp16_full_eval`) can only be used on CUDA or MLU devices or NPU devices or certain XPU devices (with IPEX).\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1615\u001B[0m     )\n\u001B[0;32m   1617\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   1618\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mframework \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1619\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m is_torch_available()\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1627\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbf16 \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbf16_full_eval)\n\u001B[0;32m   1628\u001B[0m ):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\training_args.py:2094\u001B[0m, in \u001B[0;36mTrainingArguments.device\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   2090\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   2091\u001B[0m \u001B[38;5;124;03mThe device used by this process.\u001B[39;00m\n\u001B[0;32m   2092\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   2093\u001B[0m requires_backends(\u001B[38;5;28mself\u001B[39m, [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorch\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m-> 2094\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_setup_devices\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\generic.py:63\u001B[0m, in \u001B[0;36mcached_property.__get__\u001B[1;34m(self, obj, objtype)\u001B[0m\n\u001B[0;32m     61\u001B[0m cached \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(obj, attr, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cached \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 63\u001B[0m     cached \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     64\u001B[0m     \u001B[38;5;28msetattr\u001B[39m(obj, attr, cached)\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m cached\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\training_args.py:2000\u001B[0m, in \u001B[0;36mTrainingArguments._setup_devices\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1998\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_sagemaker_mp_enabled():\n\u001B[0;32m   1999\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_accelerate_available():\n\u001B[1;32m-> 2000\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[0;32m   2001\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUsing the `Trainer` with `PyTorch` requires `accelerate>=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mACCELERATE_MIN_VERSION\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m`: \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2002\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease run `pip install transformers[torch]` or `pip install accelerate -U`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2003\u001B[0m         )\n\u001B[0;32m   2004\u001B[0m     AcceleratorState\u001B[38;5;241m.\u001B[39m_reset_state(reset_partial_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m   2005\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdistributed_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mImportError\u001B[0m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.21.0`: Please run `pip install transformers[torch]` or `pip install accelerate -U`"
     ]
    }
   ],
   "source": [
    "metric = evaluate.load(\"accuracy\")\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=data_train,\n",
    "    eval_dataset=data_valid,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T17:23:33.181824Z",
     "start_time": "2024-04-20T17:23:31.915154Z"
    }
   },
   "id": "768be02f4e27cae7",
   "execution_count": 99
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5f86add115d1ae"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "bbbd6ccda21d520c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
